{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Evaluation of the LLM 4 Model Completion Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3\n",
    "The third experiment aims at answering the research question \"Is domain-specific fine-tuning a viable alternative to few-shot learning?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_RESULTS_ADA = './../../model_completion_dataset/Synthetic/results/results_finetuning/all_results_ada.csv'\n",
    "PATH_TO_RESULTS_CURIE = './../../model_completion_dataset/Synthetic/results/results_finetuning/all_results_curie.csv'\n",
    "PATH_TO_RESULTS_DAVINCI = './../../model_completion_dataset/Synthetic/results/results_finetuning/all_results_davinci.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import all libraries. Make sure to have them installed (e.g., via pip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt # for plotting\n",
    "from scipy.stats import pearsonr # for statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we load and merge the results file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ada = pd.read_csv(PATH_TO_RESULTS_ADA, delimiter=';')\n",
    "results_curie = pd.read_csv(PATH_TO_RESULTS_CURIE, delimiter=';')\n",
    "results_davinci = pd.read_csv(PATH_TO_RESULTS_DAVINCI, delimiter=';')\n",
    "\n",
    "results_all = pd.concat([results_ada, results_curie, results_davinci])\n",
    "print(f\"We have {len(results_all)} datapoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a numeric value for the base model, to be able to correlate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model_to_numeric(base_model:str):\n",
    "    if base_model == 'ada':\n",
    "        return 1\n",
    "    elif base_model == 'curie':\n",
    "        return 2\n",
    "    elif base_model == 'davinci':\n",
    "        return 3\n",
    "    else:\n",
    "        print(\"ERROR: invalid base model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all['base_model_numeric'] = results_all['Base_Model'].apply(lambda base_model: base_model_to_numeric(base_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to identify now the best models according to average token accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all.sort_values('Average_Token_Acc', ascending=False, inplace=True)\n",
    "print(results_all[['Id', 'Epochs', 'Base_Model', 'Number_Tokens']].head(n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We correlate dataset size, base model, and epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_relevant_columns = results_all[['Diffs', 'EOs', 'Pertubation', 'Epochs', 'Number_Tokens', 'base_model_numeric', 'Average_Token_Acc']]\n",
    "\n",
    "rho = results_relevant_columns.corr()\n",
    "pval = results_relevant_columns.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "p = pval.applymap(lambda x: ''.join(['*' for t in [.05, .01, .001] if x<=t]))\n",
    "rho.round(2).astype(str) + p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3 - Part 2\n",
    "Fixing the dataset, do larger models always provide better accuracies and\n",
    "fixing the language model, do larger dataset always provide better accuracies?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = ['Diffs', 'EOs', 'Pertubation', 'Epochs', 'Number_Tokens', 'base_model_numeric', 'Average_Token_Acc']\n",
    "property_of_interest = 'EOs'\n",
    "data_ada = results_relevant_columns[results_relevant_columns['base_model_numeric'] == 1]#[['Average_Token_Acc', property_of_interest]]\n",
    "data_curie = results_relevant_columns[results_relevant_columns['base_model_numeric'] == 2]#[['Average_Token_Acc', property_of_interest]]\n",
    "data_davinci = results_relevant_columns[results_relevant_columns['base_model_numeric'] == 3]#[['Average_Token_Acc', property_of_interest]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = data_ada.corr()\n",
    "pval = data_ada.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "p = pval.applymap(lambda x: ''.join(['*' for t in [.05, .01, .001] if x<=t]))\n",
    "rho.round(2).astype(str) + p\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = data_curie.corr()\n",
    "pval = data_curie.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "p = pval.applymap(lambda x: ''.join(['*' for t in [.05, .01, .001] if x<=t]))\n",
    "rho.round(2).astype(str) + p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Davinci:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = data_davinci.corr()\n",
    "pval = data_davinci.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "p = pval.applymap(lambda x: ''.join(['*' for t in [.05, .01, .001] if x<=t]))\n",
    "rho.round(2).astype(str) + p\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm_miner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
